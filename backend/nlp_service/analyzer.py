# nlp_service/analyzer.py 
import spacy
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer, util
import numpy as np
import re
from typing import Dict, List, Tuple
import logging
import torch
import math
import pandas as pd
import os
import joblib

# Configuration du logger
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MLCVAnalyzer:
    def __init__(self, model_name='paraphrase-multilingual-MiniLM-L12-v2'):
        try:
            logger.info("Initialisation de l'analyseur de CV...")
            
            # Charger le mod√®le ML pr√©-entra√Æn√©
            self.ml_matcher = self._load_ml_model()
            
            # Charger spaCy pour le fran√ßais
            try:
                self.nlp = spacy.load("fr_core_news_sm")
                logger.info("‚úÖ Mod√®le spaCy fran√ßais charg√©")
            except OSError:
                logger.warning("spaCy non disponible, utilisation de m√©thodes simples")
                self.nlp = None
            
            # Charger les comp√©tences depuis le dataset
            self._skills_set = self._load_skills_from_dataset()
            logger.info(f"‚úÖ {len(self._skills_set)} comp√©tences charg√©es depuis le dataset")
                
        except Exception as e:
            logger.error(f"‚ùå Erreur critique lors de l'initialisation: {e}")
            raise

    def _load_ml_model(self):
        """Charge le mod√®le ML pr√©-entra√Æn√© depuis train_model.py"""
        try:
            # Chercher le mod√®le dans diff√©rents chemins
            model_paths = [
                'models/cv_job_matcher.pkl',
                os.path.join(os.path.dirname(__file__), 'models/cv_job_matcher.pkl'),
                os.path.join(os.path.dirname(os.path.dirname(__file__)), 'models/cv_job_matcher.pkl'),
            ]
            
            model_path = None
            for path in model_paths:
                if os.path.exists(path):
                    model_path = path
                    break
            
            if model_path:
                # Importer dynamiquement la classe CVJobMatcher
                # Import from the same package
                from .train_model import CVJobMatcher
                ml_model = CVJobMatcher.load_model(model_path)
                logger.info("‚úÖ Mod√®le ML charg√© avec succ√®s")
                return ml_model
            else:
                logger.warning("‚ùå Mod√®le ML non trouv√©, utilisation de l'analyse basique")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du mod√®le ML: {e}")
            return None

    def _load_skills_from_dataset(self) -> set:
        """Charge les comp√©tences depuis le dataset UpdatedResumeDataSet.csv"""
        skills_set = set()
        
        try:
            # Chercher le dataset
            dataset_paths = [
                os.path.join(os.path.dirname(__file__), 'UpdatedResumeDataSet.csv'),
                os.path.join(os.path.dirname(os.path.dirname(__file__)), 'UpdatedResumeDataSet.csv'),
                os.path.join(os.getcwd(), 'UpdatedResumeDataSet.csv'),
            ]
            
            dataset_path = None
            for path in dataset_paths:
                if os.path.exists(path):
                    dataset_path = path
                    break
            
            if not dataset_path:
                logger.warning("Dataset non trouv√©")
                return set()
            
            # Lire le dataset
            df = pd.read_csv(dataset_path, encoding='latin-1')
            logger.info(f"Dataset charg√©: {len(df)} entr√©es")
            
            # Extraire les comp√©tences de chaque CV
            for idx, row in df.iterrows():
                resume_text = str(row['Resume']).lower()
                skills_from_cv = self._extract_skills_from_resume_text(resume_text)
                skills_set.update(skills_from_cv)
            
            # Filtrer les comp√©tences valides
            skills_set = {skill for skill in skills_set if self._is_valid_skill(skill)}
            logger.info(f"Comp√©tences extraites: {len(skills_set)}")
            
            return skills_set
            
        except Exception as e:
            logger.error(f"Erreur lors du chargement du dataset: {e}")
            return set()

    def _extract_skills_from_resume_text(self, text: str) -> set:
        """Extrait les comp√©tences d'un texte de CV"""
        skills = set()
        if not text:
            return skills
        
        text = re.sub(r'\s+', ' ', text).strip().lower()
        
        # Patterns pour sections de comp√©tences
        skill_patterns = [
            r'(?:skills?|technical skills|programming skills|technologies?|tools)[:\s\-]*(.*?)(?:\n\n|\n[A-Z]|\n\s*$|$)',
            r'(?:languages?|programming languages|langages?)[:\s\-]*(.*?)(?:\n\n|\n[A-Z]|\n\s*$|$)',
        ]
        
        # Chercher dans les sections
        for pattern in skill_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE | re.DOTALL)
            for section in matches:
                # S√©parer les comp√©tences
                parts = re.split(r'[,;‚Ä¢\-\n]', section)
                for part in parts:
                    skill = self._clean_skill(part)
                    if skill:
                        skills.add(skill)
        
        return skills

    def _clean_skill(self, skill_text: str) -> str:
        """Nettoie une comp√©tence"""
        if not skill_text:
            return ""
        
        skill = skill_text.strip()
        skill = re.sub(r'[^\w\s\+#\.\/]', ' ', skill)
        skill = re.sub(r'\s+', ' ', skill).strip()
        skill = skill.lower()
        
        return skill

    def _is_valid_skill(self, skill: str) -> bool:
        """V√©rifie si une comp√©tence est valide"""
        if not skill or len(skill) < 2:
            return False
        
        excluded_words = {
            'and', 'or', 'the', 'a', 'an', 'with', 'using', 'knowledge', 'experience',
            'good', 'strong', 'excellent', 'basic', 'advanced'
        }
        
        if skill in excluded_words:
            return False
        
        if len(skill) > 50:
            return False
        
        return True

    def extract_text_from_pdf(self, pdf_file) -> str:
        """Extrait le texte d'un PDF avec gestion am√©lior√©e des erreurs et formats"""
        text = ""
        
        try:
            # Gestion du fichier (fichier upload√© ou chemin)
            file_obj = None
            if hasattr(pdf_file, 'read'):
                # Si c'est un fichier upload√©, on le r√©initialise
                pdf_file.seek(0)
                file_obj = pdf_file
                reader = PdfReader(file_obj)
            elif isinstance(pdf_file, str) and os.path.exists(pdf_file):
                # Si c'est un chemin de fichier
                with open(pdf_file, 'rb') as f:
                    reader = PdfReader(f)
            else:
                # Si c'est d√©j√† un objet PdfReader ou similaire
                reader = pdf_file
            
            # Essayer d'extraire le texte de chaque page
            for page in reader.pages:
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
                except Exception as page_error:
                    logger.warning(f"Erreur extraction page: {page_error}")
                    continue
            
            # Si aucun texte n'a √©t√© extrait, essayer une m√©thode alternative
            if not text.strip():
                logger.warning("Aucun texte extrait avec extract_text(), tentative avec extract_text(0)")
                for page in reader.pages:
                    try:
                        # Certains PDF n√©cessitent extract_text(0) au lieu de extract_text()
                        page_text = page.extract_text(0)  # Mode 0 pour une extraction plus agressive
                        if page_text and len(page_text) > 10:  # V√©rifier que le texte a une longueur minimale
                            text += page_text + "\n"
                    except Exception as alt_error:
                        logger.warning(f"Erreur extraction alternative: {alt_error}")
                        continue
            
            # Nettoyer le texte extrait
            text = self._clean_extracted_text(text)
            
            if not text.strip():
                logger.warning("Aucun texte valide extrait apr√®s nettoyage")
                return ""
                
            logger.info(f"Texte PDF extrait: {len(text)} caract√®res")
            return text
            
        except Exception as e:
            logger.error(f"Erreur critique extraction PDF: {e}", exc_info=True)
            # Essayer une derni√®re m√©thode de secours
            try:
                import io
                import PyPDF2
                
                if hasattr(pdf_file, 'read'):
                    pdf_file.seek(0)
                    pdf_data = pdf_file.read()
                elif isinstance(pdf_file, str) and os.path.exists(pdf_file):
                    with open(pdf_file, 'rb') as f:
                        pdf_data = f.read()
                else:
                    return ""
                
                # Essayer avec un nouvel objet PdfReader
                with io.BytesIO(pdf_data) as f:
                    reader = PyPDF2.PdfReader(f)
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                
                text = self._clean_extracted_text(text)
                if text.strip():
                    logger.info(f"Texte extrait avec m√©thode de secours: {len(text)} caract√®res")
                    return text
                
            except Exception as fallback_error:
                logger.error(f"√âchec de la m√©thode de secours: {fallback_error}")
            
            return ""
    
    def _clean_extracted_text(self, text: str) -> str:
        """Nettoie le texte extrait du PDF"""
        if not text:
            return ""
        
        # Remplacer les sauts de ligne multiples par un seul espace
        text = re.sub(r'\s+', ' ', text)
        
        # Supprimer les caract√®res non imprimables
        text = ''.join(char for char in text if char.isprintable() or char.isspace())
        
        # Supprimer les espaces multiples
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

    def _clean_text(self, text: str) -> str:
        """Nettoie le texte pour l'analyse"""
        if not text:
            return ""
        
        text = text.lower()
        text = re.sub(r'[^a-zA-Z0-9√†√¢√§√©√®√™√´√Æ√Ø√¥√∂√π√ª√º√ø√ß√Ä√Ç√Ñ√â√à√ä√ã√é√è√î√ñ√ô√õ√ú≈∏√á\s]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text

    def extract_skills(self, text: str) -> Dict[str, float]:
        """Extrait les comp√©tences techniques"""
        if not text or not text.strip():
            return {}
        
        if not self._skills_set:
            return {}
        
        text_lower = text.lower()
        skills_found = {}
        
        for skill in self._skills_set:
            if skill in text_lower:
                count = text_lower.count(skill)
                if count > 0:
                    weight = 1 + math.log(count)
                    skills_found[skill] = weight
        
        # Normaliser
        if skills_found:
            max_weight = max(skills_found.values())
            skills_found = {k: v/max_weight for k, v in skills_found.items()}
        
        return skills_found

    def extract_experience_years(self, text: str) -> int:
        """Extrait les ann√©es d'exp√©rience"""
        if not text:
            return 0
            
        text_lower = text.lower()
        
        patterns = [
            r'(\d+)\s*(?:ans?|ann√©es?)\s+(?:d\'?exp√©rience|d\'?exp)',
            r'exp√©rience\s*[\-:]\s*(\d+)\s*(?:ans?|ann√©es?)',
            r'(\d+)\s*(?:years?|ans?|ann√©es?)(?:\s+d\'exp√©rience|\s+exp√©rience|\s+of\s+experience)?',
            r'exp√©rience\s*:\s*(\d+\+?)\s*(?:ans?|ann√©es?)',
        ]
        
        years_found = []
        
        for pattern in patterns:
            matches = re.findall(pattern, text_lower, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple):
                    match = match[0]  # Prendre le premier groupe captur√©
                try:
                    years = int(''.join(filter(str.isdigit, str(match))))
                    years_found.append(years)
                except (ValueError, TypeError):
                    continue
        
        return max(years_found) if years_found else 0

    def calculate_compatibility(self, cv_text: str, job_description: str, pdf_file=None) -> Tuple[float, List[str], List[str]]:
        """Calcule la compatibilit√© entre CV et offre"""
        logger.info("üéØ D√©but du calcul de compatibilit√©")
        
        if not cv_text or not job_description:
            logger.warning("Texte CV ou description d'emploi manquant")
            return 0.0, [], []
        
        try:
            # Stocker la r√©f√©rence au fichier PDF pour une √©ventuelle r√©extraction
            if pdf_file:
                self.last_pdf_file = pdf_file
            
            # 1. Nettoyage initial du texte
            cv_clean = self._clean_text(cv_text)
            job_clean = self._clean_text(job_description)
            
            # V√©rifier si le texte extrait est trop court ou semble invalide
            if len(cv_clean.split()) < 10:  # Moins de 10 mots
                logger.warning("Le texte extrait du CV est trop court pour une analyse fiable")
                
                # Essayer d'extraire √† nouveau avec une m√©thode diff√©rente si possible
                if hasattr(self, 'last_pdf_file') and self.last_pdf_file:
                    logger.info("Tentative d'extraction alternative...")
                    alt_text = self.extract_text_from_pdf(self.last_pdf_file)
                    if alt_text and len(alt_text.split()) >= 10:
                        cv_clean = self._clean_text(alt_text)
                        logger.info(f"Extraction alternative r√©ussie: {len(alt_text)} caract√®res")
                    else:
                        logger.warning("L'extraction alternative n'a pas fourni de texte valide")
                
                # Si toujours pas de contenu valide, retourner un score bas mais pas nul
                if len(cv_clean.split()) < 10:
                    logger.warning("Texte CV insuffisant, utilisation d'un score minimal")
                    job_skills = self.extract_skills(job_clean)
                    return 15.0, [], list(job_skills.keys()) if job_skills else []
            
            # 2. Utiliser le mod√®le ML si disponible (60% du score)
            ml_score = 0
            if self.ml_matcher:
                try:
                    ml_score = self.ml_matcher.calculate_match_score(cv_clean, job_clean)
                    logger.info(f"ü§ñ Score ML: {ml_score}%")
                    
                    # Si le score ML est tr√®s bas, v√©rifier si c'est d√ª √† une mauvaise extraction
                    if ml_score < 10 and hasattr(self, 'last_pdf_file') and self.last_pdf_file:
                        logger.warning("Score ML tr√®s bas, v√©rification de l'extraction...")
                        alt_text = self.extract_text_from_pdf(self.last_pdf_file)
                        if alt_text and len(alt_text.split()) > len(cv_clean.split()) * 1.5:  # 50% plus de contenu
                            logger.info("Meilleur texte trouv√©, r√©essai avec le nouveau contenu")
                            return self.calculate_compatibility(alt_text, job_clean, self.last_pdf_file)
                except Exception as e:
                    logger.warning(f"Erreur mod√®le ML: {e}")
                    ml_score = 0
            
            # 3. Analyse basique avec le dataset (40% du score)
            cv_skills = self.extract_skills(cv_clean)
            job_skills = self.extract_skills(job_clean)
            
            matched_skills = []
            missing_skills = []
            basic_score = 0
            
            if job_skills:
                for skill, job_weight in job_skills.items():
                    if skill in cv_skills:
                        cv_weight = cv_skills[skill]
                        match_score = (job_weight + cv_weight) / 2
                        basic_score += match_score * 40 / len(job_skills)
                        matched_skills.append(skill)
                    else:
                        missing_skills.append(skill)
            else:
                basic_score = 12  # Score minimal
            
            # 4. Score final combin√© avec pond√©ration
            final_score = ml_score * 0.6 + basic_score
            
            # Ajustement bas√© sur la longueur du texte (p√©nalit√© pour les textes courts)
            word_count = len(cv_clean.split())
            if word_count < 50:  # Moins de 50 mots
                length_penalty = 0.5 + (word_count / 100)  # 50% √† 100% du score
                final_score *= length_penalty
                logger.info(f"Ajustement pour texte court: {length_penalty:.2f}x")
            
            # S'assurer que le score est dans une plage raisonnable
            final_score = max(0, min(100, final_score))
            
            # Ajouter une petite variation pour √©viter les ex-aequo
            import hashlib
            content_hash = int(hashlib.md5(cv_clean.encode()).hexdigest()[:8], 16)
            variation = (content_hash % 100) * 0.01  # Variation de 0 √† 1%
            final_score += variation
            final_score = round(final_score, 2)
            
            logger.info(f"üéØ Score final: {final_score}% (ML: {ml_score}%, Basique: {basic_score}%)")
            
            return final_score, matched_skills, missing_skills
            
        except Exception as e:
            logger.error(f"Erreur dans calculate_compatibility: {e}", exc_info=True)
            # Retourner un score minimal plut√¥t que 0 pour √©viter de p√©naliser trop fortement
            job_skills = self.extract_skills(job_description) if job_description else {}
            return 10.0, [], list(job_skills.keys())

    def analyze(self, cv_text: str, job_description: str, pdf_file=None) -> Dict:
        """
        Analyse compl√®te d'un CV par rapport √† une offre
        
        Args:
            cv_text: Texte extrait du CV
            job_description: Description du poste
            pdf_file: Fichier PDF optionnel pour r√©extraction si n√©cessaire
            
        Returns:
            Dictionnaire contenant les r√©sultats de l'analyse
        """
        try:
            # Calcul du score de compatibilit√©
            score, matched, missing = self.calculate_compatibility(cv_text, job_description, pdf_file)
            
            # Pr√©diction de la cat√©gorie avec ML
            try:
                category, confidence = self.predict_job_category(cv_text)
            except Exception as e:
                logger.error(f"Erreur pr√©diction cat√©gorie: {e}")
                category, confidence = "Non d√©termin√©", 0.0
            
            # Extraction des comp√©tences
            try:
                cv_skills = self.extract_skills(self._clean_text(cv_text))
                job_skills = self.extract_skills(self._clean_text(job_description))
            except Exception as e:
                logger.error(f"Erreur extraction comp√©tences: {e}")
                cv_skills = {}
                job_skills = {}
            
            # G√©n√©ration du r√©sum√©
            try:
                summary = self.summarize_cv(cv_text)
            except Exception as e:
                logger.error(f"Erreur g√©n√©ration r√©sum√©: {e}")
                summary = "R√©sum√© non disponible"
            
            # Construction du r√©sultat
            result = {
                'match_score': score,
                'matched_skills': matched,
                'missing_skills': missing,
                'cv_skills': cv_skills,
                'job_skills': job_skills,
                'job_category': category,
                'category_confidence': confidence,
                'analysis_summary': summary,
                'ml_model_used': self.ml_matcher is not None,
                'success': True
            }
            
            # Ajouter des m√©tadonn√©es de d√©bogage si n√©cessaire
            if score < 15:  # Si le score est tr√®s bas, ajouter des infos de d√©bogage
                result['debug_info'] = {
                    'cv_text_length': len(cv_text) if cv_text else 0,
                    'job_text_length': len(job_description) if job_description else 0,
                    'cv_word_count': len(cv_text.split()) if cv_text else 0,
                    'job_word_count': len(job_description.split()) if job_description else 0,
                    'cv_skills_count': len(cv_skills),
                    'job_skills_count': len(job_skills),
                }
            
            return result
            
        except Exception as e:
            logger.error(f"Erreur critique dans analyze: {e}", exc_info=True)
            return {
                'match_score': 0,
                'matched_skills': [],
                'missing_skills': [],
                'cv_skills': {},
                'job_skills': {},
                'job_category': 'Erreur',
                'category_confidence': 0,
                'analysis_summary': f'Erreur lors de l\'analyse: {str(e)}',
                'ml_model_used': False,
                'success': False,
                'error': str(e)
            }

    def summarize_cv(self, cv_text: str) -> str:
        """G√©n√®re un r√©sum√© du CV"""
        if not cv_text:
            return "Aucun contenu √† r√©sumer."
        
        # Pr√©dire la cat√©gorie si ML disponible
        if self.ml_matcher:
            category, confidence = self.predict_job_category(cv_text)
            category_info = f"Cat√©gorie pr√©dite: {category} ({confidence:.1f}% de confiance). "
        else:
            category_info = ""
        
        # Extraire l'exp√©rience
        experience = self.extract_experience_years(cv_text)
        
        # Extraire les comp√©tences principales
        skills = self.extract_skills(cv_text)
        top_skills = sorted(skills.items(), key=lambda x: x[1], reverse=True)[:5]
        
        experience_info = f"{experience} ans d'exp√©rience. " if experience > 0 else "Exp√©rience non sp√©cifi√©e. "
        skills_info = f"Comp√©tences: {', '.join([s[0] for s in top_skills])}." if top_skills else "Aucune comp√©tence d√©tect√©e."
        
        return category_info + experience_info + skills_info

    def rank_cvs(self, cvs_data: List[Dict], job_description: str) -> List[Dict]:
        """
        Classe plusieurs CVs par rapport √† une offre
        
        Args:
            cvs_data: Liste de dictionnaires [{'id': 1, 'text': '...'}, ...]
            job_description: Texte de l'offre d'emploi
            
        Returns:
            Liste tri√©e par score d√©croissant
        """
        results = []
        
        for cv_data in cvs_data:
            cv_id = cv_data.get('id')
            cv_text = cv_data.get('text', '')
            
            if not cv_text:
                continue
                
            # Analyser ce CV
            analysis = self.analyze(cv_text, job_description)
            
            results.append({
                'cv_id': cv_id,
                'match_score': analysis['match_score'],
                'job_category': analysis['job_category'],
                'category_confidence': analysis['category_confidence'],
                'matched_skills': analysis['matched_skills'],
                'missing_skills': analysis['missing_skills'],
                'analysis_summary': analysis['analysis_summary']
            })
        
        # Trier par score d√©croissant
        results.sort(key=lambda x: x['match_score'], reverse=True)
        
        return results